---
title: The what
author: Pavan Keshavamurthy
date: 2021-01-12
category: Introduction
layout: post
toc: true 
---

# Data Mesh: The Case for "What"

2021 is the year that the data mesh trend hit the high point of it's hype cycle. Unsurprisingly, there is a lot of marketing buzz around the theme that makes it difficult to specify in plain old technical terms, a descriptive vision of what a data mesh in practice might look like. To this end, we attempt to partially build on top of Zhamak et al, but may diverge in some ways from their vision. We're cognizant that this definition may evolve in the face of emerging trends, but we will attempt to disambiguate what a data mesh is, from a standpoint of what it _should technically do_, based on adjacent metaphors & first principles.

Let us first investigate then very notion of the "mesh" in the data mesh. In Wikipedia's definition,

> Network topology is the topological structure of a network and may be depicted physically or logically. It is an application of graph theory wherein communicating devices are modeled as nodes and the connections between the devices are modeled as links or lines between the nodes. Physical topology is the placement of the various components of a network (e.g., device location and cable installation), while logical topology illustrates how data flows within a network. Distances between nodes, physical interconnections, transmission rates, or signal types may differ between two different networks, yet their logical topologies may be identical.

Simply put, the data mesh is a digitally mature adaptation of the same metaphor, but wherein the communication devices (ie, the nodes)  are substituted by data producing or consuming entities, and the edges represent some process (movement, transformation) that acts upon the data in transit. The data mesh manifests in a foundational sense, as the _fabric_ in which these interactions occur, across an organization's business domain or the organization itself. 

The primary heuristic for the data mesh lies in it's _coverage_ (span) of data lifecycle and  _connectedness_ of interactions across the organization; The typical data organization of today, quite in contrast, is a wild-west of disconnected data producers & consumers. Central IT, App, Product team silos form ravines in which hypercentralized data engineering teams extract data from the modern oil rig (metaphorically), pump it large distances to storage lakes & warehouses where it is confined to further fossilization, albeit for the occasionally adventurous intervention of advanced analtics & machine learning teams which may from time to time perform groundbreaking discoveries.

The mesh model also asserts a subtle emphasis on low latency & brokered relay of data streams across the data network with fan out effects. This is in stark contrast to layered data architectures, which are strongly bounded, point to point connectivity, often with batch centric, push-pull data movement semantics 

Finally, We should also suggest that data mesh is best thought of as a _modern_ operating model for enterprise-wide data. As is the case with any operating model, or transition from one to another, the data mesh brings in aspects that touches upon People, Process & Tooling. There maybe aspects of this operating model that will map to products or platform capabilities and will closely align to cloud-native principles. 

To this end, we posit that Domain Oriented data ownership, productization, self service platform and governance are organic downstream consequences of adopting a data mesh operating model.

An A16Z Future publication on "Emerging Architectures for Modern Data Infrastructure" specifically calls out on the great convergence of AI/ML and Analytics. They narrow in on 3 data architecture blueprints, based on organizational goals; namely (1) Modern BI (2) Multi-modal data processing (3) AI and ML. We feel, architecturally, the data mesh is a best fit for customer use-cases fitting archetype (2) - Multi-modal data processing, usually with an affinity towards use-cases involving a multitude of data sources, complex transformation processes, combined with traditional and advanced analytics.


# Import concepts & abstractions

In attempting to define what a data mesh would look like, it is important to establish a few conventions & architectural abstractions based on separations of concerns. We borrow inspiration generously from networking & general distributed systems terminology that is adjacent to this problem space.

- Data Services

Data services is an abstraction for the primary constituent units of the mesh. A data service is broadly anything that interacts with the mesh, and is typically a data producing application ("publisher") or a data consuming application ("consume"); Data services operate upon an atomic unit of data, understand how data must be serialized, deserialized, marshalled and have ordering awareness. Within this spectrum, there maybe a variety of data integration concerns that they perform, which can involve complex data manipulation or transformation. Data services form the nodes of topologies and sub-topologies of the prospective mesh. 

- Data Brokers

Data brokers are abstractions that disintermediate data producers & consumers. They move data between and across a distributed mesh, whilst providing ordering & delivery guarentees, along with quality of service. 

- Mesh Data Plane

The mesh data plane is the configurable, distributed topology in which data flow & interactions between the services & the brokers occurs.

- Mesh Control Plane

The mesh control provides the policy oriented, declarative control & command the behaviour of the data plane.


# Opportunities in the mesh: Cross cutting concerns

The all encompassing coverage of a network has some interesting side-effects, which provide both upstream & downstream opportunities. The most important amongst them is providing to cover common, cross-cutting IT concerns.

- Observability

Observability means the ability to determine a system's internal state. Data processing or movement across the mesh involves several hops. The nature of the mesh provides for the ability to trace down to a single atomic unit of data and it's journey across the mesh. Another consequence of this observability to to construct the data's pedigree, also known as lineage; An associated idea is that of understanding the data's provenance (or "where it really came from"); 

- Security

The stakes around security are high. Data out of the network is fundamentally data out of control. Therefore, caution and governance must be utilized on who can access what data at any point in time; This is broadly, authentication and authorization. Data sovereignity and data principal level controls (for consent, forgettability) are overarching regulatory subjects. Therefore, the mesh can be a point of centralized policy enforcement.

- Quality of Service

All resources are finite and therefore, the mesh is a good place to place throttling functions. Quality of service covers a variety of concerns, such as enforcing quotas,  changing behaviour (ex: backpressure) or handling failures (ex: retry budgets);


# Downstream or potentially ancilliary Capabilities

- Metadata Management
- Event & Data Sourcing
- Processing

# Technology freedom & pluggable data/control plane components

- The Data Plane:
- The Control Plane: 
